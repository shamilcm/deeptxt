[model]
type = seq2seq

[network]
# num_units is the the number of GRU/LSTM/RNN units
encoder_emb_dim = 500
decoder_emb_dim = 500
encoder_units = 1024  
decoder_units = 1024
rnn_cell = gru
encoder_vocab_size = 30000
decoder_vocab_size = 30000
use_attention = True
encode_bidirectional = True

[training]
patience = 10
num_epochs = 5000
display_freq = 10
save_freq = 5000
sampling_freq = 1000
validation_freq = 50
l2_decay_penalty = 0.0
optimizer = adadelta
learning_rate = 0.0001
clip_norm = 1.0
batchsize = 32
validation_batchsize = 32
dropout = False
max_length = 50
source_train_data = /path/to/source/train/data
target_train_data = /path/to/target/train/data
source_validation_data = /path/to/source/valid/data
target_validation_data = /path/to/target/valid/data


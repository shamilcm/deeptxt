[model]
type = rnnlm

[network]
# num_units is the the number of GRU/LSTM/RNN units
emb_dim = 512
num_units = 1024  
rnn_cell = gru
vocab_size=30000

[training]
patience = 10
num_epochs = 5000
display_freq = 10
save_freq = -1
sampling_freq = 50
validation_freq = 4000
l2_decay_penalty = 0.0
optimizer = sgd
learning_rate = 0.0001
batchsize = 32
validation_batchsize=16
dropout= False
max_length = 30
train_data = /path/to/training/data
validation_data = /path/to/dev/data
